{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirczechs-Kaustubh/Finance-Sentiment-Analysis/blob/main/BNP_Paribas_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis over finance articles\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###### Author - Kaustubh Murali Prakash\n",
        "###### Email - kaushi00rg@gmail.com\n",
        "###### Date - 21/10/2024\n",
        "###### Purpose - Internship interview task for BNP Paribas"
      ],
      "metadata": {
        "id": "GKwshoXcGqL_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBRpphOMHIan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFdC4g6jnBMr"
      },
      "source": [
        "# Summary of Cells:\n",
        "1. **Install Dependencies & Initialize**: Install all necessary libraries, initialize the News API, and set up some styles.\n",
        "2. **Fetch Articles**: Provide the date range selector to fetch news articles between two dates.\n",
        "3. **Sector & Sentiment Assignment**: Classify articles into sectors and analyze their sentiment using a pre-trained model.\n",
        "4. **All Sectors Time Series Plot**: Use a date selector to visualize sentiment trends for all sectors over time.\n",
        "5. **Single Sector Time Series Plot**: Provide sector and date selectors to visualize sentiment trends for a specific sector.\n",
        "6. **Violin Plot**: Display sentiment score distributions for different sectors.\n",
        "7. **Top 3 Positive and Negative Sentiment Scoring Sectors**: Display top positive and negative sectors by weighted sentiment score in a bar chart.\n",
        "8. **Sentiment Scores vs Index**: Displays a graph showcasing the correlation between Sentiment Scores and the S&P 500 Index corresponding to the dates.\n",
        "9. **Granger Causality Test**: Determines if the Sentiment Scores have the capability of predicting the movements of S&P 500 Index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5m_Y3n-SZMO"
      },
      "source": [
        "## 1. Installing and Importing Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlvWjDjdmXVp"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install newsapi-python transformers ipywidgets statsmodels --quiet\n",
        "\n",
        "# Import required libraries\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from newsapi import NewsApiClient\n",
        "from transformers import pipeline\n",
        "from datetime import datetime, timedelta\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import seaborn as sns\n",
        "import re\n",
        "from matplotlib.dates import DateFormatter\n",
        "import yfinance as yf\n",
        "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "# Set default style for Seaborn\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Initialize Gemini API key\n",
        "genai.configure(api_key=\"AIzaSyBUrbjtfVQedQaWvnEsl7zFkIwRkXgR538\")\n",
        "# Initialize News API with your API key\n",
        "newsapi = NewsApiClient(api_key='c69a8005d32d45dcaec0f947955152c6')  # Replace with your NewsAPI key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0X4fCTHSmSy"
      },
      "source": [
        "## 2. Acquire Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the gemini model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 4000,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "  }\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"Analyze the provided image or text to extract and interpret financial data. Identify any charts, graphs, or textual content within the image and apply Optical Character Recognition (OCR) to convert visual data into analyzable text. For charts, identify the type, axes, labels, and trends. Extract key financial metrics . Analyze the trends, patterns, and any anomalies in the graphical and numerical data. Provide a comparative analysis against historical, industry or sector data, where relevant, and offer insights on the financial health and performance of the subject entity. Include any potential risks or opportunities based on the data presented in the image.\",\n",
        ")"
      ],
      "metadata": {
        "id": "WYt90lEvrMOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md89zHkamgnN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to fetch articles for a specific date\n",
        "def fetch_articles(date):\n",
        "    all_articles = newsapi.get_everything(\n",
        "        q='US recession OR recession fears',\n",
        "        from_param=date.strftime('%Y-%m-%d'),\n",
        "        to=date.strftime('%Y-%m-%d'),\n",
        "        language='en',\n",
        "        sort_by='relevancy',\n",
        "        page_size=100,\n",
        "    )\n",
        "    return all_articles['articles']\n",
        "\n",
        "# Function to collect articles between a start and end date\n",
        "def collect_articles(start_date, end_date):\n",
        "    date_list = pd.date_range(start=start_date, end=end_date)\n",
        "    articles_data = []\n",
        "\n",
        "    for date in date_list:\n",
        "        print(f\"Fetching articles for {date.date()}\")\n",
        "        articles = fetch_articles(date)\n",
        "        for article in articles:\n",
        "            articles_data.append({\n",
        "                'date': date.date(),\n",
        "                'title': article['title'],\n",
        "                'description': article['description'],\n",
        "                'content': article['content'],\n",
        "            })\n",
        "    return pd.DataFrame(articles_data)\n",
        "\n",
        "# Download S&P 500 historical data from yfinance\n",
        "def get_sp500_data(start_date, end_date):\n",
        "    sp500 = yf.download('^GSPC', start=start_date, end=end_date)\n",
        "    sp500['Return'] = sp500['Adj Close'].pct_change()  # Calculate daily returns\n",
        "    sp500 = sp500[['Return']].dropna()  # Drop rows where returns are NaN\n",
        "    return sp500\n",
        "\n",
        "# Date picker widgets for selecting the start and end dates\n",
        "start_date_widget = widgets.DatePicker(\n",
        "    description='Start Date',\n",
        "    disabled=False,\n",
        "    value=datetime.now() - timedelta(days=30)\n",
        ")\n",
        "end_date_widget = widgets.DatePicker(\n",
        "    description='End Date',\n",
        "    disabled=False,\n",
        "    value=datetime.now()\n",
        ")\n",
        "\n",
        "# Display the date picker widgets\n",
        "print(\"Please select the start and end dates for fetching articles.\")\n",
        "display(start_date_widget, end_date_widget)\n",
        "\n",
        "# Wait for the user to select the dates\n",
        "input(\"Press Enter after selecting dates...\")\n",
        "\n",
        "start_date = start_date_widget.value\n",
        "end_date = end_date_widget.value\n",
        "\n",
        "# Fetch the articles\n",
        "articles_df = collect_articles(start_date, end_date)\n",
        "\n",
        "# Fetch S&P 500 data for the same date range as the sentiment analysis articles\n",
        "sp500_data = get_sp500_data(start_date, end_date)\n",
        "\n",
        "# Combine title, description, and content into a single text column\n",
        "def preprocess_text(row):\n",
        "    text = ''\n",
        "    if row['title']:\n",
        "        text += row['title'] + '. '\n",
        "    if row['description']:\n",
        "        text += row['description'] + '. '\n",
        "    if row['content']:\n",
        "        text += row['content']\n",
        "    return text\n",
        "\n",
        "articles_df['text'] = articles_df.apply(preprocess_text, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAJDN1HuSxrO"
      },
      "source": [
        "## 3. Sector and Sentiment Mapping\n",
        "\n",
        "Maps out the sentiments and categorises into different sector based on keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95U2HEtKmkjB"
      },
      "outputs": [],
      "source": [
        "# Define sector keywords\n",
        "sector_keywords = {\n",
        "    'Technology': ['technology', 'tech', 'software', 'internet', 'AI', 'cybersecurity'],\n",
        "    'Energy': ['energy', 'oil', 'gas', 'renewable'],\n",
        "    'Finance': ['finance', 'bank', 'investment'],\n",
        "    'Healthcare': ['healthcare', 'pharmaceutical', 'medical'],\n",
        "    'Consumer Goods': ['retail', 'consumer', 'shopping'],\n",
        "    'Industrial': ['industrial', 'manufacturing'],\n",
        "    'Real Estate': ['real estate', 'housing', 'mortgage'],\n",
        "    'Transportation': ['transportation', 'logistics', 'airlines'],\n",
        "    'Other': []  # For articles that don't match any sector\n",
        "}\n",
        "\n",
        "# Compile sector patterns using regex\n",
        "sector_patterns = {}\n",
        "for sector, keywords in sector_keywords.items():\n",
        "    pattern = r'\\b(' + '|'.join([re.escape(keyword.lower()) for keyword in keywords]) + r')\\b'\n",
        "    sector_patterns[sector] = re.compile(pattern)\n",
        "\n",
        "# Function to identify sectors based on keywords\n",
        "def identify_sectors(text):\n",
        "    text_lower = text.lower()\n",
        "    sectors_found = set()\n",
        "    for sector, pattern in sector_patterns.items():\n",
        "        if pattern.search(text_lower):\n",
        "            sectors_found.add(sector)\n",
        "    return list(sectors_found) if sectors_found else ['Other']\n",
        "\n",
        "# Apply the sector identification function\n",
        "articles_df['sectors'] = articles_df['text'].apply(identify_sectors)\n",
        "\n",
        "# Sentiment analysis using pre-trained BERT model\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    #device = 0\n",
        ")\n",
        "\n",
        "texts = articles_df['text'].fillna('').str[:512].tolist()\n",
        "results = sentiment_pipeline(texts)\n",
        "\n",
        "# Convert results into a DataFrame\n",
        "sentiment_results = pd.DataFrame(results)\n",
        "\n",
        "# Assign sentiment scores and map sentiments\n",
        "def map_sentiment_label(label):\n",
        "    return 'Positive' if label == 'NEGATIVE' else 'Negative'\n",
        "\n",
        "sentiment_results['sentiment'] = sentiment_results['label'].apply(map_sentiment_label)\n",
        "sentiment_mapping = {'Positive': 1, 'Negative': -1}\n",
        "sentiment_results['sentiment_score'] = sentiment_results['sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# Merge sentiments back to the main DataFrame\n",
        "articles_df['sentiment'] = sentiment_results['sentiment']\n",
        "articles_df['sentiment_score'] = sentiment_results['sentiment_score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic5hkOEIcAyW"
      },
      "outputs": [],
      "source": [
        "sentiment_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iGGMnosS8W2"
      },
      "source": [
        "## 4. Time Series Plot for All sectors\n",
        "\n",
        "Time series representation of sentiments across all the sectors within a given range (time range can be changed using the calender function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNVg01hgmnBH"
      },
      "outputs": [],
      "source": [
        "# Group by date and sectors to calculate average sentiment score\n",
        "sector_sentiment = articles_df.explode('sectors').groupby(['date', 'sectors'])['sentiment_score'].mean().reset_index()\n",
        "\n",
        "# Convert 'date' column to datetime\n",
        "sector_sentiment['date'] = pd.to_datetime(sector_sentiment['date'])\n",
        "\n",
        "# Save some rows of the dataframe to give gemini a better context\n",
        "output1 = str(sector_sentiment.head(10))\n",
        "\n",
        "# Date range widgets for the first plot (all sectors over time)\n",
        "start_date_picker1 = widgets.DatePicker(description='Start Date', value=sector_sentiment['date'].min().date())\n",
        "end_date_picker1 = widgets.DatePicker(description='End Date', value=sector_sentiment['date'].max().date())\n",
        "\n",
        "print(\"Select date range for all sectors:\")\n",
        "#display(start_date_picker1, end_date_picker1)\n",
        "\n",
        "# Function to plot sentiment over time for all sectors\n",
        "def plot_all_sectors_over_time(start_date, end_date):\n",
        "    if start_date is None or end_date is None:\n",
        "        print(\"Please select both start and end dates.\")\n",
        "        return\n",
        "    start_date = pd.to_datetime(start_date)\n",
        "    end_date = pd.to_datetime(end_date)\n",
        "\n",
        "    filtered_data = sector_sentiment[\n",
        "        (sector_sentiment['date'] >= start_date) &\n",
        "        (sector_sentiment['date'] <= end_date)\n",
        "    ]\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        print(\"No data available for the selected date range.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sns.lineplot(\n",
        "        data=filtered_data,\n",
        "        x='date',\n",
        "        y='sentiment_score',\n",
        "        hue='sectors',\n",
        "        marker='o',\n",
        "        palette='tab10'\n",
        "    )\n",
        "    plt.title('Sector Sentiment Over Time')\n",
        "    plt.ylabel('Average Sentiment Score')\n",
        "    plt.xlabel('Date')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Sector', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig('sector_sentiment.png')\n",
        "\n",
        "# Interactive plot for all sectors\n",
        "interact(plot_all_sectors_over_time, start_date=start_date_picker1, end_date=end_date_picker1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transportation, Consumer Goods, and Finance sectors show extreme volatility, frequently oscillating between high positive (+1.0) and low negative sentiment (-1.0).\n",
        "\n",
        "Healthcare and Other sectors show relatively smoother, more consistent sentiment scores, mostly remaining close to neutral (0).\n",
        "\n",
        "Around October 1st and October 9th, several sectors, including Technology and Industrial, experience sharp drops into negative sentiment, possibly reflecting industry-wide events or crises that influenced public perception during these periods."
      ],
      "metadata": {
        "id": "BubyFfXkF9rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_plot = genai.upload_file(path=\"content/sector_sentiment.png\",\n",
        "                            display_name=\"SentimentPlot\")\n",
        "response1 = model.generate_content([sentiment_plot, \"Provide key insights, analysis of sector sentiment trends, and potential financial implications from this chart, focusing on only the main takeaways and avoiding unnecessary details.\"])"
      ],
      "metadata": {
        "id": "QN1PEz2zzRdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Tp5LblTGN2"
      },
      "source": [
        "## 5. Time Series Analysis for a selected sector\n",
        "\n",
        "Time series representation of sentiments across a single selected sector in a given time range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b2_tytXmoug"
      },
      "outputs": [],
      "source": [
        "# Dropdown to select sector and date range\n",
        "sector_selector_single = widgets.Dropdown(\n",
        "    options=sorted(sector_sentiment['sectors'].unique()),\n",
        "    value='Technology',\n",
        "    description='Sector'\n",
        ")\n",
        "start_date_picker2 = widgets.DatePicker(description='Start Date', value=sector_sentiment['date'].min().date())\n",
        "end_date_picker2 = widgets.DatePicker(description='End Date', value=sector_sentiment['date'].max().date())\n",
        "\n",
        "print(\"Select sector and date range for plotting:\")\n",
        "#display(sector_selector_single, start_date_picker2, end_date_picker2)\n",
        "\n",
        "# Function to plot sentiment over time for a specific sector\n",
        "def plot_single_sector_over_time(sector, start_date, end_date):\n",
        "    if not sector or not start_date or not end_date:\n",
        "        print(\"Please select sector and date range.\")\n",
        "        return\n",
        "    start_date = pd.to_datetime(start_date)\n",
        "    end_date = pd.to_datetime(end_date)\n",
        "\n",
        "    filtered_data = sector_sentiment[\n",
        "        (sector_sentiment['sectors'] == sector) &\n",
        "        (sector_sentiment['date'] >= start_date) &\n",
        "        (sector_sentiment['date'] <= end_date)\n",
        "    ]\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        print(f\"No data available for {sector} sector in the selected range.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sns.lineplot(\n",
        "        data=filtered_data,\n",
        "        x='date',\n",
        "        y='sentiment_score',\n",
        "        marker='o',\n",
        "        color='blue'\n",
        "    )\n",
        "    plt.title(f'Sentiment Over Time for {sector} Sector')\n",
        "    plt.ylabel('Average Sentiment Score')\n",
        "    plt.xlabel('Date')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig('single_sector_sentiment.png')\n",
        "\n",
        "# Interactive plot for single sector\n",
        "interact(plot_single_sector_over_time, sector=sector_selector_single, start_date=start_date_picker2, end_date=end_date_picker2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sector_sentiment_plot = genai.upload_file(path=\"content/single_sector_sentiment.png\",\n",
        "                            display_name=\"SingleSentimentPlot\")\n",
        "response2 = model.generate_content([sector_sentiment_plot, \"Provide key insights, analysis of this particular sector sentiment trends, and potential financial implications from this chart, focusing on only the main takeaways and avoiding unnecessary details.\"])"
      ],
      "metadata": {
        "id": "a9SS3S-13AoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9bKFcz4TMBt"
      },
      "source": [
        "## 6. Visualisation of Sentiment Distribution\n",
        "\n",
        "Distribution of Sentiments as a violin plot in order to check for over represented or under represented sectors in the news articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa-b0bApmrWN"
      },
      "outputs": [],
      "source": [
        "# Function to plot violin plot for the overall sentiment distribution by sector\n",
        "def plot_sentiment_violin_fill(data):\n",
        "    sns.set_style('whitegrid')\n",
        "    fig_height = 1.2 * len(data['sectors'].unique())\n",
        "\n",
        "    plt.figure(figsize=(12, fig_height))\n",
        "    sns.violinplot(\n",
        "        data=data,\n",
        "        x='sentiment_score',\n",
        "        y='sectors',\n",
        "        inner='stick',\n",
        "        linewidth=1.5,\n",
        "        palette='Set2'\n",
        "    )\n",
        "\n",
        "    sns.despine(left=True, bottom=True)\n",
        "    plt.title('Distribution of Sentiment Scores by Sector', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Sentiment Score', fontsize=12)\n",
        "    plt.ylabel('Sector', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig('violin_plot.png')\n",
        "\n",
        "# Plot the violin plot using the data from articles_exploded_df\n",
        "plot_sentiment_violin_fill(articles_df.explode('sectors'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "violin_plot = genai.upload_file(path=\"content/violin_plot.png\",\n",
        "                            display_name=\"ViolinPlot\")\n",
        "response3 = model.generate_content([violin_plot, \"Provide key insights, analysis of this particular graph that represents the distribution of sentiment scores across sectors, and potential financial implications from this chart, focusing on only the main takeaways and avoiding unnecessary details.\"])"
      ],
      "metadata": {
        "id": "eRIekKUl3f0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ichwUbVVTglJ"
      },
      "source": [
        "## 7. High Sentiment Scoring Sector vs Low Sentiment Scoring Sector\n",
        "\n",
        "Comparison Top 3 and Bottom 3 sectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6u2AUNvm8Cv"
      },
      "outputs": [],
      "source": [
        "# Widgets for selecting date range for top positive and negative sectors\n",
        "start_date_picker3 = widgets.DatePicker(\n",
        "    description='Start Date',\n",
        "    value=sector_sentiment['date'].min().date()\n",
        ")\n",
        "end_date_picker3 = widgets.DatePicker(\n",
        "    description='End Date',\n",
        "    value=sector_sentiment['date'].max().date()\n",
        ")\n",
        "\n",
        "print(\"Select date range for top 3 positive and negative sectors:\")\n",
        "#display(start_date_picker3, end_date_picker3)\n",
        "\n",
        "# Function to plot top 3 positive and top 3 negative sectors\n",
        "def plot_top_sectors(data, start_date, end_date):\n",
        "    # Filter data by date range\n",
        "    if start_date is None or end_date is None:\n",
        "        print(\"Please select a date range.\")\n",
        "        return\n",
        "\n",
        "    start_date = pd.to_datetime(start_date)\n",
        "    end_date = pd.to_datetime(end_date)\n",
        "\n",
        "    filtered_data = data[\n",
        "        (data['date'] >= start_date) &\n",
        "        (data['date'] <= end_date)\n",
        "    ]\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        print(\"No data available for the selected date range.\")\n",
        "        return\n",
        "\n",
        "    # Calculate total sentiment score and count for each sector\n",
        "    sector_stats = filtered_data.groupby('sectors').agg(\n",
        "        total_sentiment=('sentiment_score', 'sum'),\n",
        "        count=('sectors', 'size')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Calculate weighted sentiment score\n",
        "    sector_stats['weighted_sentiment'] = sector_stats['total_sentiment'] / sector_stats['count']\n",
        "\n",
        "    # Sort and extract top 3 positive and top 3 negative sectors\n",
        "    top_positive = sector_stats.sort_values(by='weighted_sentiment', ascending=False).head(3)\n",
        "    top_negative = sector_stats.sort_values(by='weighted_sentiment').head(3)\n",
        "\n",
        "    # Concatenate top positive and negative sectors\n",
        "    top_sectors = pd.concat([top_positive, top_negative])\n",
        "\n",
        "    # Define color for positive and negative sectors\n",
        "    top_sectors['color'] = ['Positive' if x >= 0 else 'Negative' for x in top_sectors['weighted_sentiment']]\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Use different colors for top positive and negative sectors\n",
        "    sns.barplot(\n",
        "        x='weighted_sentiment',\n",
        "        y='sectors',\n",
        "        data=top_sectors,\n",
        "        hue='color',\n",
        "        dodge=False,\n",
        "        palette={'Positive': 'green', 'Negative': 'red'}  # Green for top 3, Red for bottom 3\n",
        "    )\n",
        "\n",
        "    # Add a horizontal line between the top and bottom performers\n",
        "    plt.axhline(y=2.5, color='black', linestyle='--', linewidth=2)  # Line between the third and fourth bars\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.title('Top 3 Positive and Negative Sectors by Weighted Sentiment Score', fontsize=16, fontweight='bold', color='darkblue')\n",
        "    plt.xlabel('Weighted Sentiment Score', fontsize=14, fontweight='bold', color='darkblue')\n",
        "    plt.ylabel('Sectors', fontsize=14, fontweight='bold', color='darkblue')\n",
        "    plt.xticks(fontsize=12, color='black')\n",
        "    plt.yticks(fontsize=12, color='black')\n",
        "    plt.grid(True, which='major', axis='x', linestyle='--', alpha=0.7)\n",
        "    sns.despine(left=True, bottom=False)\n",
        "\n",
        "    # Customize legend\n",
        "    plt.legend(title=\"Sentiment Type\", loc=\"upper right\", fontsize=12, title_fontsize=14, frameon=True, shadow=True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "    plt.savefig('top_vs_low.png')\n",
        "\n",
        "# Interactive plot for top sectors\n",
        "interact(\n",
        "    plot_top_sectors,\n",
        "    data=fixed(sector_sentiment),\n",
        "    start_date=start_date_picker3,\n",
        "    end_date=end_date_picker3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_low_plot = genai.upload_file(path=\"content/top_vs_low.png\",\n",
        "                            display_name=\"TopLowPlot\")\n",
        "response4 = model.generate_content([top_low_plot, \"Provide key insights and description analysis of this particular graph that represents the top 3 sectors with high sentiment score and bottom 3 sectors with lowset sentiment score, and potential financial implications from this chart, focusing on only the main takeaways and avoiding unnecessary details.\"])"
      ],
      "metadata": {
        "id": "2jLJqOdO4yll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given time range 20 Septemeber to 20 October 2024, the top three sectors that had the best performance in terms of sentiment analysis was 1) Healthcare 2) Energy 3) Transportation.\n",
        "\n",
        "While the least performing three sectors were 1) Real Estate 2) Finance 3) Technology"
      ],
      "metadata": {
        "id": "1CCX6Z_zFLjh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_VLe0p_TsKS"
      },
      "source": [
        "## 8. Plot of Sentiment Score vs S&P 500 Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j39qwrMj5K0r"
      },
      "outputs": [],
      "source": [
        "sector_sentiment['date'] = pd.to_datetime(sector_sentiment['date'])\n",
        "\n",
        "daily_sentiment = sector_sentiment.groupby('date')['sentiment_score'].mean().reset_index()\n",
        "\n",
        "merged_data = pd.merge(daily_sentiment, sp500_data, left_on='date', right_index=True, how='inner')\n",
        "\n",
        "def plot_sentiment_vs_index(merged_data):\n",
        "\n",
        "    # Step 1: Calculate the correlation\n",
        "    correlation = merged_data['sentiment_score'].corr(merged_data['Return'])\n",
        "    print(f\"Correlation between sentiment and S&P 500 returns: {correlation:.4f}\")\n",
        "\n",
        "    # Step 2: Plot the time series\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    # Plot average sentiment scores\n",
        "    plt.plot(merged_data['date'], merged_data['sentiment_score'], label='Average Sentiment Score', color='blue')\n",
        "\n",
        "    # Plot S&P 500 returns (scaled to match sentiment scores)\n",
        "    plt.plot(merged_data['date'], merged_data['Return'], label='S&P 500 Daily Returns', color='orange')\n",
        "\n",
        "    plt.title(f'Sentiment Score vs S&P 500 Returns (Aligned Dates) - Correlation: {correlation:.4f}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig('sentiment_vs_index.png')\n",
        "\n",
        "    return correlation\n",
        "\n",
        "correlation_score = plot_sentiment_vs_index(merged_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_sentiment = genai.upload_file(path=\"content/sentiment_vs_index.png\",\n",
        "                            display_name=\"IndexVSSentiment\")\n",
        "response5 = model.generate_content([index_sentiment, \"Provide key insights and description analysis of this particular graph that represents the average sentiment scores compared to S&P500 Index, and potential financial implications from this chart, focusing on only the main takeaways and avoiding unnecessary details.\"])"
      ],
      "metadata": {
        "id": "NSiX7BDL8WEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot indicated a slight negative correlation of sentiment scores with S&P 500 index but not a significant correlation."
      ],
      "metadata": {
        "id": "0RR0F3cDE-iv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDMcm7qw8uE3"
      },
      "source": [
        "## 8. Time Series Causality Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5BzhSbn81Pt"
      },
      "outputs": [],
      "source": [
        "# Check stationarity with Augmented Dickey-Fuller test\n",
        "def check_stationarity(series, name):\n",
        "    result = adfuller(series)\n",
        "    print(f'ADF Statistic for {name}: {result[0]:.4f}')\n",
        "    print(f'p-value for {name}: {result[1]:.4f}')\n",
        "    if result[1] < 0.05:\n",
        "        print(f\"{name} is stationary.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"{name} is not stationary, differencing is required. \\n\")\n",
        "        return False\n",
        "\n",
        "# Differencing if necessary to make the time series stationary\n",
        "def make_stationary(series):\n",
        "    return series.diff().dropna()\n",
        "\n",
        "# Defining Granger causality test function\n",
        "def perform_granger_causality(sentiment_series, return_series):\n",
        "    # Combine the two series into a DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'Sentiment': sentiment_series,\n",
        "        'Return': return_series\n",
        "    }).dropna()\n",
        "\n",
        "    # Determine the maximum lag allowable based on the number of observations\n",
        "    max_lag = min(4, len(df) // 2)  # Restrict lag based on available observations, cap it at 4\n",
        "    print(f\"Performing Granger causality test with maximum allowable lag of {max_lag}...\")\n",
        "\n",
        "    # Perform Granger causality test\n",
        "    granger_results = grangercausalitytests(df[['Return', 'Sentiment']], max_lag, verbose=False)\n",
        "\n",
        "    # Loop over results and extract p-values\n",
        "    significant_lags = []\n",
        "    for lag in granger_results:\n",
        "        p_value = granger_results[lag][0]['ssr_chi2test'][1]  # Extracting p-value\n",
        "        print(f\"Lag {lag}: p-value = {p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            significant_lags.append(lag)\n",
        "\n",
        "    if significant_lags:\n",
        "        print(f\"Granger causality found for lags: {significant_lags}\")\n",
        "    else:\n",
        "        print(\"No Granger causality found.\")\n",
        "\n",
        "    return significant_lags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKOzWynM9Ki0"
      },
      "outputs": [],
      "source": [
        "sentiment_stationary = merged_data['sentiment_score']  # Defaults to original data\n",
        "returns_stationary = merged_data['Return']  # Defaults to original data\n",
        "\n",
        "if not check_stationarity(merged_data['sentiment_score'], 'Sentiment Score'):\n",
        "    sentiment_stationary = make_stationary(merged_data['sentiment_score'])\n",
        "\n",
        "if not check_stationarity(merged_data['Return'], 'S&P 500 Returns'):\n",
        "    returns_stationary = make_stationary(merged_data['Return'])\n",
        "\n",
        "# Performing the Granger causality test\n",
        "test_result = perform_granger_causality(sentiment_stationary, returns_stationary)\n",
        "\n",
        "# Checking the results and make a conclusion\n",
        "if test_result:\n",
        "    print(\"Sentiment Scores provide predictive information for future returns.\")\n",
        "else:\n",
        "    print(\"Sentiment Scores do not provide predictive information, consider using a different dataset or better keywords.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gct_result = str(test_result)\n",
        "response6 = model.generate_content(gct_result+\"\\n Give me the insights on the results of Granger Causality Test when sentiment scores of News Articles from US Recession Fears when compared to the S&P 500 index, do not generate additional or unrequired infromation, make sure the content produced have meaningful financial insights\")"
      ],
      "metadata": {
        "id": "EhOqhaIu9l_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Granger Causality Test revealed that the sentiment data had no significant correlation or influence over the market trends of S&P 500 Index. And thus can be concluded that sentiment scores are not a good measure to predict market trends.\n",
        "Although this could be due to the limitations in the dataset as the news articles were only obtained of 30 days, the analysis and the report can be made much robust by incorporating more articles from longer periods."
      ],
      "metadata": {
        "id": "hEbi1NJJEQbi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuaA1TFrT6Lu"
      },
      "source": [
        "## 9. Final Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGzGSkyT_oK"
      },
      "outputs": [],
      "source": [
        "report_text = response1.text+\"\\n\\n\"+response2.text+\"\\n\\n\"+response3.text+\"\\n\\n\"+response4.text+\"\\n\\n\"+response5.text+\"\\n\\n\"+response6.text\n",
        "print(\"Report\\n\"+report_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Report Highlights"
      ],
      "metadata": {
        "id": "vnr3sziO_OMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the gemini model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8000,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "  }\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"Summarise the provided text to extract and interpret financial data. Identify and Include any potential risks or opportunities based on the data presented in the image.\",\n",
        ")\n",
        "\n",
        "highlights = model.generate_content(report_text+\"\\n Give me a structured summary and insights of the above text provided. Please highlight important financial insights and whether predictive analysis can be employed based on the provided data.\")\n",
        "print(highlights.text)"
      ],
      "metadata": {
        "id": "XG6KSbjj_NY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMWsl+jxymQ/BM0Av/YQRzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}